{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The convolutif model like the deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as py\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ModelConvolutif model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConvolutif():\n",
    "\n",
    "    def __init__(self,tailImg,ncol,nclasses,nhidden):\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        self.tailImg,self.ncol=tailImg,ncol\n",
    "        self.x=tf.placeholder(tf.float32,shape=[None, tailImg,tailImg,ncol])\n",
    "        self.y=tf.placeholder(tf.float32,shape=[None,nclasses])\n",
    "        self.prob=tf.placeholder(tf.float32)\n",
    "        self.filtr,self.conv,self.b,self.nhidden,self.nclas=None,None,None,nhidden,nclasses\n",
    "        self.tf_session,self.t=tf.Session(),0\n",
    "\n",
    "    def convolution(self,taille=5,nfiltr=100):\n",
    "        if self.t==0 :\n",
    "            self.filtrage(taille,nfiltr)\n",
    "            self.conv=tf.nn.conv2d(self.x,self.filtr,strides=[1,1,1,1],padding=\"SAME\") +self.b\n",
    "        else :\n",
    "            self.filtrage(taille,nfiltr)\n",
    "            self.conv=tf.nn.conv2d(self.conv,self.filtr,strides=[1,1,1,1],padding=\"SAME\") +self.b\n",
    "        self.conv=tf.nn.relu(self.conv)\n",
    "        self.maxPool()\n",
    "\n",
    "    def filtrage(self,taille=5,nfiltr=50):\n",
    "        if self.t==0 :\n",
    "            p=int(self.x.get_shape()[-1])\n",
    "        else :\n",
    "            p=int(self.conv.get_shape()[-1])\n",
    "        self.t=1\n",
    "        self.filtr=tf.Variable(tf.truncated_normal(shape=(taille,taille,p,nfiltr)))\n",
    "        self.b=tf.Variable(tf.zeros([nfiltr]))\n",
    "\n",
    "    def maxPool(self):\n",
    "        if self.t==1:\n",
    "            self.conv=tf.nn.max_pool(self.conv,strides=[1,2,2,1],ksize=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "    def getFlatten(self):\n",
    "        if self.t==0:\n",
    "            return None\n",
    "        return tf.contrib.layers.flatten(self.conv)\n",
    "\n",
    "    def train(self,lr,sizet,sizebatch,datatrain):\n",
    "        if self.t==0:\n",
    "            return None\n",
    "        vecteur=self.getFlatten()\n",
    "        self.w1=tf.Variable(tf.truncated_normal(shape=[int(vecteur.get_shape()[-1]),self.nhidden]))\n",
    "        self.b1=tf.Variable(tf.zeros([self.nhidden]))\n",
    "        self.h1=tf.nn.relu(tf.matmul(vecteur,self.w1) +self.b1)\n",
    "        self.w2=tf.Variable(tf.truncated_normal(shape=[self.nhidden,self.nclas]))\n",
    "        self.b2=tf.Variable(tf.zeros([self.nclas]))\n",
    "        self.h2=tf.matmul(self.h1,self.w2) +self.b2\n",
    "        self.soft=tf.nn.softmax(self.h2)\n",
    "        self.cross_entropy=tf.nn.softmax_cross_entropy_with_logits(labels=self.y,logits=self.h2)\n",
    "        self.error=tf.reduce_mean(self.cross_entropy)\n",
    "        eq=tf.equal(tf.argmax(self.soft,1),tf.argmax(self.y,1))\n",
    "        self.accy=tf.reduce_mean(tf.cast(eq,\"float\"))\n",
    "        self.optim=tf.train.AdamOptimizer(lr).minimize(self.error)\n",
    "        self.tf_session.run(tf.global_variables_initializer())\n",
    "        self.acc=[]\n",
    "        self.erre=[]\n",
    "        for i in range(sizet):\n",
    "            images,labels=datatrain.next_batch(sizebatch)\n",
    "            images=images.reshape(sizebatch,self.tailImg,self.tailImg,self.ncol)\n",
    "            d={self.x:images,self.y:labels,self.prob:0.5}\n",
    "            _,a,er,r=self.tf_session.run([self.optim,self.accy,self.error,self.x],feed_dict=d)\n",
    "            self.acc.append(a)\n",
    "            self.erre.append(er)\n",
    "            \n",
    "    def predict(self,image):\n",
    "        h=self.tf_session.run(self.soft,feed_dict={self.x:[image.reshape(self.tailImg,self.tailImg,self.ncol)]})\n",
    "        return py.argmax(h)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Imported the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=input_data.read_data_sets(\"input/data\",one_hot=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "instanciation of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convol=ModelConvolutif(28,1,10,1)\n",
    "convol.convolution(8,32)\n",
    "convol.convolution(5,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convol.train(0.1,100,100,data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convol.acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convol.predict(data.train.images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.labels[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
